{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=88000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "\n",
    "word_index = {k : (v + 3) for k, v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding='post', maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding='post', maxlen=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(88000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          1408000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,408,289\n",
      "Trainable params: 1,408,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.6924 - accuracy: 0.5294 - val_loss: 0.6906 - val_accuracy: 0.6147\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 70us/sample - loss: 0.6874 - accuracy: 0.6719 - val_loss: 0.6836 - val_accuracy: 0.7406\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 70us/sample - loss: 0.6756 - accuracy: 0.7569 - val_loss: 0.6680 - val_accuracy: 0.7638\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 69us/sample - loss: 0.6518 - accuracy: 0.7829 - val_loss: 0.6404 - val_accuracy: 0.7351\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 69us/sample - loss: 0.6138 - accuracy: 0.8075 - val_loss: 0.6006 - val_accuracy: 0.7970\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 74us/sample - loss: 0.5626 - accuracy: 0.8297 - val_loss: 0.5530 - val_accuracy: 0.8113\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 70us/sample - loss: 0.5054 - accuracy: 0.8499 - val_loss: 0.5040 - val_accuracy: 0.8248\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 71us/sample - loss: 0.4493 - accuracy: 0.8668 - val_loss: 0.4594 - val_accuracy: 0.8386\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 70us/sample - loss: 0.3980 - accuracy: 0.8837 - val_loss: 0.4214 - val_accuracy: 0.8494\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.3539 - accuracy: 0.8962 - val_loss: 0.3903 - val_accuracy: 0.8597\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.3167 - accuracy: 0.9052 - val_loss: 0.3663 - val_accuracy: 0.8647\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.2850 - accuracy: 0.9137 - val_loss: 0.3462 - val_accuracy: 0.8709\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 85us/sample - loss: 0.2583 - accuracy: 0.9209 - val_loss: 0.3313 - val_accuracy: 0.8739\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 81us/sample - loss: 0.2351 - accuracy: 0.9287 - val_loss: 0.3184 - val_accuracy: 0.8779\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.2147 - accuracy: 0.9367 - val_loss: 0.3084 - val_accuracy: 0.8794\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.1967 - accuracy: 0.9427 - val_loss: 0.3008 - val_accuracy: 0.8828\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.1812 - accuracy: 0.9476 - val_loss: 0.2950 - val_accuracy: 0.8834\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.1669 - accuracy: 0.9525 - val_loss: 0.2889 - val_accuracy: 0.8854\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.1537 - accuracy: 0.9581 - val_loss: 0.2847 - val_accuracy: 0.8872\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 85us/sample - loss: 0.1418 - accuracy: 0.9629 - val_loss: 0.2818 - val_accuracy: 0.8868\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 86us/sample - loss: 0.1309 - accuracy: 0.9669 - val_loss: 0.2792 - val_accuracy: 0.8870\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 82us/sample - loss: 0.1215 - accuracy: 0.9696 - val_loss: 0.2781 - val_accuracy: 0.8878\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.1123 - accuracy: 0.9734 - val_loss: 0.2781 - val_accuracy: 0.8875\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.1043 - accuracy: 0.9763 - val_loss: 0.2763 - val_accuracy: 0.8884\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 80us/sample - loss: 0.0965 - accuracy: 0.9795 - val_loss: 0.2769 - val_accuracy: 0.8885\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 83us/sample - loss: 0.0897 - accuracy: 0.9809 - val_loss: 0.2760 - val_accuracy: 0.8896\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.0834 - accuracy: 0.9832 - val_loss: 0.2771 - val_accuracy: 0.8895\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 84us/sample - loss: 0.0776 - accuracy: 0.9847 - val_loss: 0.2773 - val_accuracy: 0.8893\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0724 - accuracy: 0.9863 - val_loss: 0.2805 - val_accuracy: 0.8891\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 93us/sample - loss: 0.0675 - accuracy: 0.9873 - val_loss: 0.2798 - val_accuracy: 0.8885\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 93us/sample - loss: 0.0628 - accuracy: 0.9889 - val_loss: 0.2818 - val_accuracy: 0.8896\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.0587 - accuracy: 0.9899 - val_loss: 0.2836 - val_accuracy: 0.8895\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 88us/sample - loss: 0.0550 - accuracy: 0.9907 - val_loss: 0.2871 - val_accuracy: 0.8884\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0511 - accuracy: 0.9921 - val_loss: 0.2877 - val_accuracy: 0.8889\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 91us/sample - loss: 0.0481 - accuracy: 0.9925 - val_loss: 0.2897 - val_accuracy: 0.8886\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 87us/sample - loss: 0.0452 - accuracy: 0.9931 - val_loss: 0.2931 - val_accuracy: 0.8879\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.0422 - accuracy: 0.9939 - val_loss: 0.2946 - val_accuracy: 0.8882\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 89us/sample - loss: 0.0398 - accuracy: 0.9941 - val_loss: 0.2974 - val_accuracy: 0.8876\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 91us/sample - loss: 0.0369 - accuracy: 0.9951 - val_loss: 0.3002 - val_accuracy: 0.8874\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.0349 - accuracy: 0.9955 - val_loss: 0.3038 - val_accuracy: 0.8869\n"
     ]
    }
   ],
   "source": [
    "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 32us/sample - loss: 0.3382 - accuracy: 0.8722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33818242547512056, 0.87224]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    \n",
    "    for word in s:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word.lower()])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked the movie and I didn't walk into the cinema assuming it will be trash. I didn't go there to compare with the 1994 movie. I just enjoyed it. Now I can see a lot of 1-star reviews and I am shocked, because 90% of them have no intelligent arguments as to why this movie gets such horrible ratings. So, I won't make an exception and I won't give any explanation for this 10-star review. I loved every minute and also, I almost cried at some scenes.\n",
      "[[   1   13  423    4   20    5   13  161 1135   83    4  438 5683   12\n",
      "    80   30 1157   13  161  140   50    8 1661   19    4 6114   20   13\n",
      "    43  510   12  150   13   70   67    6  176    7    2  857    5   13\n",
      "   244 2414   88    2    7   98   28   57 1089 6702   17    8  138   14\n",
      "    20  214  141  527 2896   38   13  528   97   35 1401    5   13  528\n",
      "   202  101 1823   18   14    2  733   13  447  175  786    5   82   13\n",
      "   220 3785   33   49  139    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[0.33014628]\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"\\\"\", \"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
    "        predict = model.predict(encode)\n",
    "        print(line)\n",
    "        print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
